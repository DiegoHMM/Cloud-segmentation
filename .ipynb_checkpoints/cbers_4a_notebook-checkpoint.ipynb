{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import random\n",
    "from osgeo import gdal\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"D:/cbers_data/DataSetModelo/\"\n",
    "\n",
    "SCENES_PATH = \"D:/cbers_data/DataSetModelo/raw_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(image):\n",
    "    \n",
    "    return((image-np.nanmin(image))/(np.nanmax(image)- np.nanmin(image)))\n",
    "\n",
    "def resize_img(image,x,y,z):\n",
    "    image = cv2.resize(image,(x,y))\n",
    "    image = image.reshape((x,y,z))\n",
    "    return image\n",
    "\n",
    "#def clip_image(r,g,b,n):\n",
    "#    return np.dstack((r,g,b,n))\n",
    "\n",
    "def print_cbers_image(image):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing the raw imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating folders\n",
    "\n",
    "try:\n",
    "    folders = ['train_frames', 'train_masks', 'val_frames', 'val_masks', 'test_frames', 'test_masks']\n",
    "    for folder in folders:\n",
    "        os.makedirs(DATA_PATH + folder)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating folders\n",
    "try:\n",
    "    folders = ['train_frames', 'train_masks', 'val_frames', 'val_masks', \n",
    "               'test_frames', 'test_masks']\n",
    "    for folder in folders:\n",
    "        os.makedirs(DATA_PATH + folder)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = ['CBERS_4A_WFI_20201020_205_116_L4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset files\n",
    "all_frames = FILES\n",
    "random.seed(4)\n",
    "random.shuffle(all_frames)\n",
    "\n",
    "train_size = int(1 * len(all_frames))\n",
    "#val_size = int(0.15 * len(all_frames))\n",
    "#test_size = int(0.15 * len(all_frames))\n",
    "\n",
    "train_scene = all_frames[:train_size]\n",
    "#val_scene = all_frames[train_size:train_size+val_size]\n",
    "#test_scene = val_subscenes = all_frames[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate corresponding mask lists for masks\n",
    "train_masks = [f for f in all_frames if f in train_scene]\n",
    "#val_masks = [f for f in all_frames if f in val_scene]\n",
    "#test_masks = [f for f in all_frames if f in test_scene]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_image(input_path, output_path,image_name):\n",
    "    \n",
    "    red = gdal.Open(input_path + image_name + '_BAND13_GRID_SURFACE.tif')\n",
    "    green = gdal.Open(input_path + image_name + '_BAND14_GRID_SURFACE.tif')\n",
    "    blue = gdal.Open(input_path + image_name + '_BAND15_GRID_SURFACE.tif')\n",
    "    #nir = gdal.Open(input_path + image_name + '_BAND16_GRID_SURFACE.tif')\n",
    "    #Create the .vrt from RGBN\n",
    "    array = [red, green, blue]#adicionar o nir\n",
    "    opt = gdal.BuildVRTOptions(srcNodata=-9999, VRTNodata=-9999,separate=True,resampleAlg='nearest')\n",
    "    vrt_clip = gdal.BuildVRT(input_path + image_name +'.vrt', array, options=opt)\n",
    "    #Translate the .vrt to .tif\n",
    "    trans_opt = gdal.TranslateOptions(format=\"tif\", outputType=gdal.gdalconst.GDT_Unknown, \n",
    "                                  bandList=[1,2,3],width=0, height=0, widthPct=0.0, \n",
    "                                  heightPct=0.0, xRes=0.0, yRes=0.0,noData=-9999)\n",
    "    \n",
    "    return gdal.Translate(output_path + image_name +'_rgbn.tif', vrt_clip)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crop_image_rgbn(output_dir, rgbn, image_name, dimension):\n",
    "    gt = rgbn.GetGeoTransform()\n",
    "    x_min = gt[0]\n",
    "    y_max = gt[3]\n",
    "\n",
    "    res = gt[1]\n",
    "\n",
    "    num_img_x = rgbn.RasterXSize/dimension\n",
    "    num_img_y = rgbn.RasterYSize/dimension\n",
    "\n",
    "    x_len = res * rgbn.RasterXSize\n",
    "    y_len = res * rgbn.RasterYSize\n",
    "\n",
    "    x_size = x_len/num_img_x\n",
    "    y_size = y_len/num_img_y\n",
    "\n",
    "\n",
    "    x_steps = [x_min + x_size * i for i in range(int(num_img_x) + 1)]\n",
    "    y_steps = [y_max - y_size * i for i in range(int(num_img_y) + 1)]\n",
    "    print(\"qnt img x: \" + str(num_img_x))\n",
    "    print(\"qnt img y: \" + str(num_img_y))\n",
    "    index_img = 0\n",
    "    for i in range(int(num_img_x)):\n",
    "        for j in range(int(num_img_y)):\n",
    "            x_min = x_steps[i]\n",
    "            x_max = x_steps[i+1]\n",
    "            y_max = y_steps[j]\n",
    "            y_min = y_steps[j+1]\n",
    "            index_img+=1\n",
    "\n",
    "            gdal.Warp(output_dir + image_name+ \"_\" + str(i)+ \"_\" +str(j)+'_'+str(index_img)+\"_\"+\".tif\", rgbn, \n",
    "                      outputBounds = (x_min,y_min,x_max, y_max), dstNodata = -9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add train, val frames and masks to relevant folders\n",
    "from numpy import save\n",
    "\n",
    "def add_frames(dir_name, image_name):\n",
    "    try:\n",
    "        dir_name = \"D:/cbers_data/DataSetModelo/\" + dir_name + '/'\n",
    "        #clip Image\n",
    "        raw_path = \"D:/cbers_data/DataSetModelo/raw_data/\" \n",
    "        clip_path = \"D:/cbers_data/DataSetModelo/clip/\" \n",
    "        clip_img = clip_image(raw_path, clip_path,image_name)\n",
    "        #crop image\n",
    "        crop_image_rgbn(dir_name, clip_img, image_name, DIMENSION)\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "def add_masks(dir_name, image_name):\n",
    "    try:\n",
    "        dir_name = \"D:/cbers_data/DataSetModelo/\" + dir_name + '/'\n",
    "        #crop image\n",
    "        mask = gdal.Open(\"D:/cbers_data/DataSetModelo/raw_data/\" + image_name + '_CMASK_GRID_SURFACE.tif')\n",
    "        crop_image_rgbn(dir_name, mask, image_name, DIMENSION)\n",
    " \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_scene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-289-64d8dc036cdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mframe_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scene\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_frames'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_scene\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val_frames'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_scene\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_frames'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmask_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_masks'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val_masks'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_masks'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_scene' is not defined"
     ]
    }
   ],
   "source": [
    "frame_folders = [(train_scene, 'train_frames'), (val_scene, 'val_frames'), (test_scene, 'test_frames')]\n",
    "\n",
    "mask_folders = [(train_masks, 'train_masks'), (val_masks, 'val_masks'), (test_masks, 'test_masks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_folders = [(train_scene, 'train_frames')]\n",
    "\n",
    "mask_folders = [(train_masks, 'train_masks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['CBERS_4A_WFI_20201020_205_116_L4'], 'train_frames')\n",
      "qnt img x: 61.16015625\n",
      "qnt img y: 63.6171875\n",
      "(['CBERS_4A_WFI_20201020_205_116_L4'], 'train_masks')\n",
      "qnt img x: 61.16015625\n",
      "qnt img y: 63.6171875\n"
     ]
    }
   ],
   "source": [
    "#Celula que carrega as imagens nos diretórios corretos\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Add frames\n",
    "for folder in frame_folders:\n",
    "    print(folder)\n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "    list(map(add_frames, name, array))\n",
    "\n",
    "# Add masks\n",
    "for folder in mask_folders:\n",
    "    print(folder)\n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "    list(map(add_masks, name, array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        data_format=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "'D:/Geoprocessamento/DataSetModelo/l8_biome/train_frames',\n",
    "batch_size = BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def data_gen(img_folder, mask_folder, batch_size):\n",
    "    c = 0\n",
    "    n = os.listdir(img_folder) #List of training images\n",
    "    random.shuffle(n)\n",
    "    x,y,z = DIMENSION,DIMENSION,1\n",
    "    while(True):\n",
    "        img = np.zeros((batch_size, DIMENSION, DIMENSION, 3)).astype('float')\n",
    "        mask = np.zeros((batch_size, DIMENSION, DIMENSION, 1)).astype('float')\n",
    "\n",
    "        for i in range(c, c + batch_size): #initially from 0 to 16, c = 0. \n",
    "            #train_img = np.load(img_folder+'/'+n[i], allow_pickle=True)\n",
    "            train_img = gdal.Open(img_folder+'/'+n[i]).ReadAsArray()\n",
    "\n",
    "            #train_img =  cv2.resize(train_img, (256, 256))# Read an image from folder and resize\n",
    "            #train_img = train_img.reshape(256, 256, 4)\n",
    "            #Normalização\n",
    "            train_img = cv2.normalize(train_img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "            #train_img = normalize_min_max(train_img)\n",
    "            train_img = tf.convert_to_tensor(train_img.transpose((1,2,0)))\n",
    "            img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
    "\n",
    "            #n[i] = n[i][:-3] + \"tif\"\n",
    "            \n",
    "            train_mask = gdal.Open(mask_folder+'/'+n[i]).ReadAsArray()\n",
    "            #train_mask = (np.load(mask_folder+'/'+n[i]))\n",
    "            train_mask = train_mask/1\n",
    "            #train_mask = cv2.resize(train_mask, (256, 256))\n",
    "            train_mask = resize_img(train_mask,x,y,z)\n",
    "            #train_mask = normalize_min_max(train_mask)\n",
    "            train_mask = cv2.normalize(train_mask, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            #train_mask = np.expand_dims(train_mask,axis=2)\n",
    "            train_mask = np.expand_dims(train_mask, axis=2)\n",
    "            train_mask = tf.convert_to_tensor(train_mask)\n",
    "            \n",
    "            mask[i-c] = train_mask\n",
    "            \n",
    "\n",
    "        c += batch_size\n",
    "        \n",
    "        if(c + batch_size >= len(os.listdir(img_folder))):\n",
    "            c=0\n",
    "            random.shuffle(n)\n",
    "                      # print \"randomizing again\"\n",
    "        \n",
    "        yield img, mask\n",
    "        \n",
    "train_frame_path = 'D:/cbers_data/DataSetModelo/train_frames'\n",
    "train_mask_path = 'D:/cbers_data/DataSetModelo/train_masks'\n",
    "\n",
    "val_frame_path = 'D:/cbers_data/DataSetModelo/val_frames'\n",
    "val_mask_path = 'D:/cbers_data/DataSetModelo/val_masks'\n",
    "\n",
    "test_frame_path = 'D:/cbers_data/DataSetModelo/test_frames'\n",
    "test_mask_path = 'D:/cbers_data/DataSetModelo/test_masks'\n",
    "\n",
    "train_gen = data_gen(train_frame_path,train_mask_path, batch_size = BATCH_SIZE)\n",
    "val_gen = data_gen(val_frame_path,val_mask_path, batch_size = BATCH_SIZE)\n",
    "test_gen = data_gen(test_frame_path,test_mask_path, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NO_OF_TRAINING_IMAGES = len(os.listdir(train_frame_path))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir(val_frame_path))\n",
    "weights_path = 'D:/cbers_data/DataSetModelo/'\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_path, monitor='f1', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "csv_logger = CSVLogger('D:/cbers_data/DataSetModelo/log.out', append=True, separator=';')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'f1', verbose = 1,\n",
    "                              min_delta = 0.01, patience = 20, mode = 'max')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, earlystopping]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "\n",
    "inputs = Input((DIMENSION, DIMENSION, 3))\n",
    "s = (inputs)\n",
    "\n",
    "c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\",f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, ZeroPadding2D\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "visualkeras.layered_view(model,legend=True, scale_xy=0.5, scale_z=0.5, max_z=7, to_file='network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training the model\n",
    "model_history = model.fit(train_gen, \n",
    "                    epochs = 64, \n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    validation_data = val_gen, \n",
    "                    callbacks = callbacks_list,\n",
    "                    steps_per_epoch =(NO_OF_TRAINING_IMAGES/BATCH_SIZE), \n",
    "                    validation_steps = (NO_OF_VAL_IMAGES/BATCH_SIZE)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "\n",
    "\n",
    "def get_test_batch(qnt_images):\n",
    "    evaluate = []\n",
    "    \n",
    "    convert_to_image = keras.preprocessing.image.array_to_img\n",
    "    dir_images = test_frame_path\n",
    "    dir_masks = test_mask_path\n",
    "    test_files = os.listdir(test_frame_path)\n",
    "    #batch_images_structure\n",
    "    mask_true_image_test = np.zeros((qnt_images,DIMENSIO,DIMENSIO,1))\n",
    "    batch_test_images = np.zeros((qnt_images,DIMENSIO,DIMENSIO,3))\n",
    "\n",
    "    for i in range(qnt_images):\n",
    "        #mask_test = np.load(dir_masks + '/'+ test_files[i], allow_pickle=True)\n",
    "        #mask_test = mask_test / 1\n",
    "        #mask_test = cv2.resize(mask_test, (512,512))\n",
    "        #mask_test = np.expand_dims(mask_test,axis=2)\n",
    "        #mask_test = normalize_min_max(mask_test)\n",
    "        mask_test = gdal.Open(dir_masks + '/'+ test_files[i]).ReadAsArray()\n",
    "        #ask_test = mask_test.transpose((1,2,0))\n",
    "        mask_test = cv2.normalize(mask_test, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        mask_test = np.expand_dims(mask_test, axis=2)\n",
    "\n",
    "        \n",
    "        #imagem_teste = np.load(dir_images + '/'+ test_files[i],allow_pickle=True)\n",
    "        imagem_teste = gdal.Open(dir_images + '/'+ test_files[i]).ReadAsArray()\n",
    "        imagem_teste = imagem_teste.transpose((1,2,0))\n",
    "        imagem_teste = cv2.normalize(imagem_teste, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "        #imagem_teste = cv2.resize(imagem_teste, (512, 512))\n",
    "        #imagem_teste = cv2.resize(imagem_teste, (512, 512))\n",
    "        #imagem_teste = normalize_min_max(imagem_teste)\n",
    "        \n",
    "        y_eval = np.expand_dims(mask_test, axis=0)\n",
    "        x_eval = np.expand_dims(imagem_teste, axis=0)\n",
    "        \n",
    "        evaluate.append(model.evaluate(x=x_eval,y=y_eval))\n",
    "        \n",
    "        mask_true_image_test [i,:,:] = mask_test\n",
    "        batch_test_images [i,:,:] = imagem_teste\n",
    "    return batch_test_images, mask_true_image_test, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnt_images = 50\n",
    "batch_test_images, mask_true_image_test, evaluate = get_test_batch(qnt_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluate)\n",
    "df_eval.columns = [\"Loss\", \"Accuracy\", \"f1\"]\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Loss: ' + str(df_eval['Loss'].mean()))\n",
    "print( 'F1: ' + str(df_eval['f1'].mean()))\n",
    "print( 'Accuracy: ' + str(df_eval['Accuracy'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_predict = model.predict(batch_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    \n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(qnt_images):\n",
    "    b, g, r  = batch_test_images[i][:, :, 0], batch_test_images[i][:, :, 1], batch_test_images[i][:, :, 2]\n",
    "    rgb = np.dstack((r,g,b))\n",
    "    show_images([rgb, mask_true_image_test[i], mask_predict[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = model_history.history['f1']\n",
    "val_f1 = model_history.history['val_f1']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(f1, label='Training F1-Score')\n",
    "plt.plot(val_f1, label='Validation F1-Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation F1-Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "croped = 'D:/cbers_data/DataSetModelo/train_frames/'\n",
    "list_image = glob.glob(croped + \"CBERS_4A_WFI_20201020_205_116_L4_*_*_*_.tif\")\n",
    "sorted(list_image, key=lambda x: int(x.split('_')[11]))\n",
    "g = gdal.Warp(\"output.tif\", list_image)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
