{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import random\n",
    "from osgeo import gdal, osr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"D:/cbers_data/DataSetModelo/\"\n",
    "RAW_DATA_DIR = \"D:/cbers_data/DataSetModelo/raw_scene/\"\n",
    "RAW_MASK_DIR = \"D:/cbers_data/DataSetModelo/raw_mask/\"\n",
    "CLIPPED_DATA_DIR = \"D:/cbers_data/DataSetModelo/clip/\"\n",
    "VRT_DATA_DIR = \"D:/cbers_data/DataSetModelo/vrt/\"\n",
    "PREDICT_DIR = \"D:/cbers_data/DataSetModelo/predict/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(image):\n",
    "    \n",
    "    return((image-np.nanmin(image))/(np.nanmax(image)- np.nanmin(image)))\n",
    "\n",
    "def resize_img(image,x,y,z):\n",
    "    image = cv2.resize(image,(x,y))\n",
    "    image = image.reshape((x,y,z))\n",
    "    return image\n",
    "\n",
    "def print_cbers_image(image):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = 256\n",
    "BANDS = 3\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing the raw imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"D:/cbers_data/DataSetModelo/CALIBRATING_MODEL/\"\n",
    "TRAINING_PATH = \"D:/cbers_data/DataSetModelo/CALIBRATING_MODEL/Training/\"\n",
    "SCENES_DIR = \"D:/cbers_data/DataSetModelo/CALIBRATING_MODEL/Scenes/\"\n",
    "MASKS_DIR = \"D:/cbers_data/DataSetModelo/CALIBRATING_MODEL/Masks/\"\n",
    "NORMALIZED_DIR = \"D:/cbers_data/DataSetModelo/CALIBRATING_MODEL/Normalized_scenes/\"\n",
    "VRT_DATA_DIR = \"D:/cbers_data/DataSetModelo/CALIBRATING_MODEL/vrt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.handle_data import create_training_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training folders\n",
    "create_training_folders(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data to clipped image (Necessário quando as imagens estão separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all files from raw_data\n",
    "FILES = os.listdir(SCENES_DIR)\n",
    "#get name of files\n",
    "FILES = [i.split('_BAND', 1)[0] for i in FILES]\n",
    "#remove duplicateds\n",
    "FILES = list(dict.fromkeys(FILES))\n",
    "#Clip All images first\n",
    "for image in FILES:\n",
    "    clip_image(SCENES_DIR,CLIPPED_DATA_DIR,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_SCENES_LIST = os.listdir(SCENES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.normalize impo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_Y_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    r = driver.Create(filename, t.RasterXSize, t.RasterYSize, 3, gdal.GDT_Byte,['COMPRESS=LZW'])\n",
    "\n",
    "    # Set metadata\n",
    "    r.SetGeoTransform(t.GetGeoTransform())\n",
    "    r.SetProjection(t.GetProjection())\n",
    "\n",
    "    # loop through bands and write new values\n",
    "    for bix in range(3):\n",
    "\n",
    "        rb = r.GetRasterBand(bix+1)\n",
    "\n",
    "        # Write array\n",
    "        rb.WriteArray(arr[...,bix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset files\n",
    "all_frames = os.listdir(CLIPPED_DATA_DIR)\n",
    "random.seed(12)\n",
    "random.shuffle(all_frames)\n",
    "\n",
    "train_size = int(0.7 * len(all_frames))\n",
    "val_size = int(0.25 * len(all_frames))\n",
    "test_size = int(0.5 * len(all_frames))\n",
    "\n",
    "\n",
    "train_scene = all_frames[:train_size]\n",
    "val_scene = all_frames[train_size:train_size+val_size]\n",
    "test_scene = val_subscenes = all_frames[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate corresponding mask lists for masks\n",
    "train_masks = [f for f in all_frames if f in train_scene]\n",
    "val_masks = [f for f in all_frames if f in val_scene]\n",
    "test_masks = [f for f in all_frames if f in test_scene]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crop_image_rgbn(output_dir, rgbn, image_name, dimension):\n",
    "    gt = rgbn.GetGeoTransform()\n",
    "    x_min = gt[0]\n",
    "    y_max = gt[3]\n",
    "\n",
    "    res = gt[1]\n",
    "\n",
    "    num_img_x = rgbn.RasterXSize/dimension\n",
    "    num_img_y = rgbn.RasterYSize/dimension\n",
    "\n",
    "    x_len = res * rgbn.RasterXSize\n",
    "    y_len = res * rgbn.RasterYSize\n",
    "\n",
    "    x_size = x_len/num_img_x\n",
    "    y_size = y_len/num_img_y\n",
    "\n",
    "\n",
    "    x_steps = [x_min + x_size * i for i in range(int(num_img_x) + 1)]\n",
    "    y_steps = [y_max - y_size * i for i in range(int(num_img_y) + 1)]\n",
    "    print(\"qnt img x: \" + str(num_img_x))\n",
    "    print(\"qnt img y: \" + str(num_img_y))\n",
    "    index_img = 0\n",
    "    for i in range(int(num_img_x)):\n",
    "        for j in range(int(num_img_y)):\n",
    "            x_min = x_steps[i]\n",
    "            x_max = x_steps[i+1]\n",
    "            y_max = y_steps[j]\n",
    "            y_min = y_steps[j+1]\n",
    "            index_img+=1\n",
    "            print(output_dir + image_name+ \"_\" + str(i)+ \"_\" +str(j)+'_'+str(index_img)+\"_\"+\".tif\")\n",
    "            gdal.Warp(output_dir + image_name+ \"_\" + str(i)+ \"_\" +str(j)+'_'+str(index_img)+\"_\"+\".tif\", rgbn, \n",
    "                      outputBounds = (x_min,y_min,x_max, y_max), dstNodata = -9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add train, val frames and masks to relevant folders\n",
    "from numpy import save\n",
    "\n",
    "def add_frames(dir_name, image_name):\n",
    "    try:\n",
    "        image_name = image_name.split('_rgbn')[0]\n",
    "        output_dir = DATA_PATH + dir_name + '/'\n",
    "        #crop image\n",
    "        clipped_image = gdal.Open(CLIPPED_DATA_DIR + image_name +'_rgbn.tif')\n",
    "        \n",
    "        crop_image_rgbn(output_dir, clipped_image, image_name, DIMENSION)\n",
    "        \n",
    "    except Exception as e: \n",
    "        #print(e)\n",
    "        pass\n",
    "    \n",
    "def add_masks(dir_name, image_name):\n",
    "    try:\n",
    "        image_name = image_name.split('_rgbn')[0]\n",
    "        dir_name = DATA_PATH + dir_name + '/'\n",
    "        #crop image\n",
    "        mask = gdal.Open(RAW_MASK_DIR + image_name + '_CMASK_GRID_SURFACE.tif')\n",
    "        crop_image_rgbn(dir_name, mask, image_name, DIMENSION)\n",
    " \n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame_folders = [(train_scene, 'train_frames'), (val_scene, 'val_frames'), (test_scene, 'test_frames')]\n",
    "\n",
    "mask_folders = [(train_masks, 'train_masks'), (val_masks, 'val_masks'), (test_masks, 'test_masks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celula que carrega as imagens nos diretórios corretos\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Add masks\n",
    "for folder in mask_folders:\n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "    list(map(add_masks, name, array))\n",
    "\n",
    "# Add frames\n",
    "for folder in frame_folders:\n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "    list(map(add_frames, name, array))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        data_format=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "'D:/cbers_data/DataSetModelo/train_frames',\n",
    "batch_size = BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def data_gen(img_folder, mask_folder, batch_size):\n",
    "    c = 0\n",
    "    n = os.listdir(img_folder) #List of training images\n",
    "    random.shuffle(n)\n",
    "    x,y,z = DIMENSION,DIMENSION,1\n",
    "    while(True):\n",
    "        img = np.zeros((batch_size, DIMENSION, DIMENSION, 3)).astype('float')\n",
    "        mask = np.zeros((batch_size, DIMENSION, DIMENSION, 1)).astype('float')\n",
    "\n",
    "        for i in range(c, c + batch_size): #initially from 0 to 16, c = 0. \n",
    "            #train_img = np.load(img_folder+'/'+n[i], allow_pickle=True)\n",
    "            train_img = gdal.Open(img_folder+'/'+n[i]).ReadAsArray()\n",
    "\n",
    "            #train_img =  cv2.resize(train_img, (256, 256))# Read an image from folder and resize\n",
    "            #train_img = train_img.reshape(256, 256, 4)\n",
    "            #Normalização\n",
    "            train_img = cv2.normalize(train_img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "            #train_img = normalize_min_max(train_img)\n",
    "            train_img = tf.convert_to_tensor(train_img.transpose((1,2,0)))\n",
    "            img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
    "\n",
    "            #n[i] = n[i][:-3] + \"tif\"\n",
    "            \n",
    "            train_mask = gdal.Open(mask_folder+'/'+n[i]).ReadAsArray()\n",
    "            #train_mask = (np.load(mask_folder+'/'+n[i]))\n",
    "            train_mask = train_mask/1\n",
    "            #train_mask = cv2.resize(train_mask, (256, 256))\n",
    "            train_mask = resize_img(train_mask,x,y,z)\n",
    "            #train_mask = normalize_min_max(train_mask)\n",
    "            train_mask = cv2.normalize(train_mask, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            #train_mask = np.expand_dims(train_mask,axis=2)\n",
    "            train_mask = np.expand_dims(train_mask, axis=2)\n",
    "            train_mask = tf.convert_to_tensor(train_mask)\n",
    "            \n",
    "            mask[i-c] = train_mask\n",
    "            \n",
    "\n",
    "        c += batch_size\n",
    "        \n",
    "        if(c + batch_size >= len(os.listdir(img_folder))):\n",
    "            c=0\n",
    "            random.shuffle(n)\n",
    "                      # print \"randomizing again\"\n",
    "        \n",
    "        yield img, mask\n",
    "        \n",
    "train_frame_path = 'D:/cbers_data/DataSetModelo/train_frames'\n",
    "train_mask_path = 'D:/cbers_data/DataSetModelo/train_masks'\n",
    "\n",
    "val_frame_path = 'D:/cbers_data/DataSetModelo/val_frames'\n",
    "val_mask_path = 'D:/cbers_data/DataSetModelo/val_masks'\n",
    "\n",
    "test_frame_path = 'D:/cbers_data/DataSetModelo/test_frames'\n",
    "test_mask_path = 'D:/cbers_data/DataSetModelo/test_masks'\n",
    "\n",
    "train_gen = data_gen(train_frame_path,train_mask_path, batch_size = BATCH_SIZE)\n",
    "val_gen = data_gen(val_frame_path,val_mask_path, batch_size = BATCH_SIZE)\n",
    "test_gen = data_gen(test_frame_path,test_mask_path, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NO_OF_TRAINING_IMAGES = len(os.listdir(train_frame_path))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir(val_frame_path))\n",
    "weights_path = 'D:/cbers_data/DataSetModelo/'\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_path, monitor='f1', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "csv_logger = CSVLogger('D:/cbers_data/DataSetModelo/log.out', append=True, separator=';')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'f1', verbose = 1,\n",
    "                              min_delta = 0.01, patience = 5, mode = 'max')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, earlystopping]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "\n",
    "inputs = Input((DIMENSION, DIMENSION, 3))\n",
    "s = (inputs)\n",
    "\n",
    "c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\",f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, ZeroPadding2D\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "visualkeras.layered_view(model,legend=True, scale_xy=0.5, scale_z=0.5, max_z=7, to_file='network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training the model\n",
    "model_history = model.fit(train_gen, \n",
    "                    epochs = 15, \n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    validation_data = val_gen, \n",
    "                    callbacks = callbacks_list,\n",
    "                    steps_per_epoch =(NO_OF_TRAINING_IMAGES/BATCH_SIZE), \n",
    "                    validation_steps = (NO_OF_VAL_IMAGES/BATCH_SIZE)\n",
    "                  )\n",
    "\n",
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "\n",
    "\n",
    "def get_test_batch(qnt_images):\n",
    "    evaluate = []\n",
    "    \n",
    "    convert_to_image = keras.preprocessing.image.array_to_img\n",
    "    dir_images = test_frame_path\n",
    "    dir_masks = test_mask_path\n",
    "    test_files = os.listdir(test_frame_path)\n",
    "    #batch_images_structure\n",
    "    mask_true_image_test = np.zeros((qnt_images,DIMENSION,DIMENSION,1))\n",
    "    batch_test_images = np.zeros((qnt_images,DIMENSION,DIMENSION,3))\n",
    "\n",
    "    for i in range(qnt_images):\n",
    "        mask_test = gdal.Open(dir_masks + '/'+ test_files[i]).ReadAsArray()\n",
    "        mask_test = cv2.normalize(mask_test, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        mask_test = np.expand_dims(mask_test, axis=2)\n",
    "\n",
    "        imagem_teste = gdal.Open(dir_images + '/'+ test_files[i]).ReadAsArray()\n",
    "        imagem_teste = imagem_teste.transpose((1,2,0))\n",
    "        imagem_teste = cv2.normalize(imagem_teste, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "        \n",
    "        y_eval = np.expand_dims(mask_test, axis=0)\n",
    "        x_eval = np.expand_dims(imagem_teste, axis=0)\n",
    "        \n",
    "        evaluate.append(model.evaluate(x=x_eval,y=y_eval))\n",
    "        \n",
    "        mask_true_image_test [i,:,:] = mask_test\n",
    "        batch_test_images [i,:,:] = imagem_teste\n",
    "    return batch_test_images, mask_true_image_test, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnt_images = 500\n",
    "batch_test_images, mask_true_image_test, evaluate = get_test_batch(qnt_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluate)\n",
    "df_eval.columns = [\"Loss\", \"Accuracy\", \"f1\"]\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Loss: ' + str(df_eval['Loss'].mean()))\n",
    "print( 'F1: ' + str(df_eval['f1'].mean()))\n",
    "print( 'Accuracy: ' + str(df_eval['Accuracy'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_predict = model.predict(batch_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'CMask', 'Predicted Mask']\n",
    "\n",
    "    \n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(qnt_images):\n",
    "    b, g, r  = batch_test_images[i][:, :, 0], batch_test_images[i][:, :, 1], batch_test_images[i][:, :, 2]\n",
    "    rgb = np.dstack((r,g,b))\n",
    "    show_images([rgb, mask_true_image_test[i], mask_predict[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = model_history.history['f1']\n",
    "val_f1 = model_history.history['val_f1']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(f1, label='Training F1-Score')\n",
    "plt.plot(val_f1, label='Validation F1-Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation F1-Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "croped = 'D:/cbers_data/DataSetModelo/train_frames/'\n",
    "list_image = glob.glob(croped + \"CBERS_4A_WFI_20201020_205_116_L4_*_*_*_.tif\")\n",
    "sorted(list_image, key=lambda x: int(x.split('_')[11]))\n",
    "g = gdal.Warp(\"output.tif\", list_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO JA TREINADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recarregamento do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import random\n",
    "from osgeo import gdal\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"D:/cbers_data/DataSetModelo/\"\n",
    "RAW_DATA_DIR = \"D:/cbers_data/DataSetModelo/raw_scene/\"\n",
    "RAW_MASK_DIR = \"D:/cbers_data/DataSetModelo/raw_mask/\"\n",
    "CLIPPED_DATA_DIR = \"D:/cbers_data/DataSetModelo/clip/\"\n",
    "VRT_DATA_DIR = \"D:/cbers_data/DataSetModelo/vrt/\"\n",
    "PREDICT_DIR = \"D:/cbers_data/DataSetModelo/predict/\"\n",
    "DIMENSION = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(image):\n",
    "    \n",
    "    return((image-np.nanmin(image))/(np.nanmax(image)- np.nanmin(image)))\n",
    "\n",
    "def resize_img(image,x,y,z):\n",
    "    image = cv2.resize(image,(x,y))\n",
    "    image = image.reshape((x,y,z))\n",
    "    return image\n",
    "\n",
    "def print_cbers_image(image):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_image(input_path, output_path,image_name):\n",
    "    red = gdal.Open(input_path + image_name + '_BAND13_GRID_SURFACE.tif')\n",
    "    green = gdal.Open(input_path + image_name + '_BAND14_GRID_SURFACE.tif')\n",
    "    blue = gdal.Open(input_path + image_name + '_BAND15_GRID_SURFACE.tif')\n",
    "    #nir = gdal.Open(input_path + image_name + '_BAND16_GRID_SURFACE.tif')\n",
    "    #Create the .vrt from RGBN\n",
    "    #array = [red, green, blue,/nir]#adicionar o nir\n",
    "    array = [red, green, blue]#adicionar o nir\n",
    "    opt = gdal.BuildVRTOptions(srcNodata=-9999, VRTNodata=-9999,separate=True,resampleAlg='nearest')\n",
    "    vrt_clip = gdal.BuildVRT(VRT_DATA_DIR + image_name +'.vrt', array, options=opt)\n",
    "    #Translate the .vrt to .tif\n",
    "    trans_opt = gdal.TranslateOptions(format=\"tif\", outputType=gdal.gdalconst.GDT_Unknown, \n",
    "                                  bandList=[1,2,3],width=0, height=0, widthPct=0.0, \n",
    "                                  heightPct=0.0, xRes=0.0, yRes=0.0,noData=-9999)\n",
    "    #Clip da imagem\n",
    "    gdal.Translate(output_path + image_name +'_rgbn.tif', vrt_clip)\n",
    "    #Apaga o vrt\n",
    "    #os.remove(image_name + \".vrt\") \n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_rgbn(output_dir, rgbn, image_name, dimension):\n",
    "    gt = rgbn.GetGeoTransform()\n",
    "    x_min = gt[0]\n",
    "    y_max = gt[3]\n",
    "\n",
    "    res = gt[1]\n",
    "\n",
    "    num_img_x = rgbn.RasterXSize/dimension\n",
    "    num_img_y = rgbn.RasterYSize/dimension\n",
    "\n",
    "    x_len = res * rgbn.RasterXSize\n",
    "    y_len = res * rgbn.RasterYSize\n",
    "\n",
    "    x_size = x_len/num_img_x\n",
    "    y_size = y_len/num_img_y\n",
    "\n",
    "\n",
    "    x_steps = [x_min + x_size * i for i in range(int(num_img_x) + 1)]\n",
    "    y_steps = [y_max - y_size * i for i in range(int(num_img_y) + 1)]\n",
    "    print(\"qnt img x: \" + str(num_img_x))\n",
    "    print(\"qnt img y: \" + str(num_img_y))\n",
    "    index_img = 0\n",
    "    for i in range(int(num_img_x)):\n",
    "        for j in range(int(num_img_y)):\n",
    "            x_min = x_steps[i]\n",
    "            x_max = x_steps[i+1]\n",
    "            y_max = y_steps[j]\n",
    "            y_min = y_steps[j+1]\n",
    "            index_img+=1\n",
    "            \n",
    "            gdal.Warp(output_dir + image_name+ \"_\" + str(i)+ \"_\" +str(j)+'_'+str(index_img)+\"_\"+\".tif\", rgbn, \n",
    "                      outputBounds = (x_min,y_min,x_max, y_max), dstNodata = -9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "TESTE_FRAME_DIR = 'D:/cbers_data/DataSetModelo/test_frames/'\n",
    "TESTE_MASK_DIR = 'D:/cbers_data/DataSetModelo/test_masks/'\n",
    "# Load image\n",
    "\n",
    "test_frames_list = glob.glob(TESTE_FRAME_DIR + \"CBERS_4A_WFI_20201025_235_108_L4_*_*_*_.tif\")\n",
    "test_masks_list = glob.glob(TESTE_MASK_DIR + \"CBERS_4A_WFI_20201025_235_108_L4_*_*_*_.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QNT_SUB_FRAMES = len(test_frames_list)\n",
    "test_images = np.zeros((QNT_SUB_FRAMES,DIMENSION,DIMENSION,3))\n",
    "\n",
    "for i, ele in enumerate(test_frames_list):\n",
    "    image_test = gdal.Open(ele).ReadAsArray()\n",
    "    image_test = image_test.transpose((1,2,0))\n",
    "    image_test = cv2.normalize(image_test, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    test_images [i,:,:] = image_test\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image_test))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRGB(template,arr,filename):\n",
    "    '''Creates a copy of a 3-band raster with values from array\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        template: Path to template raster\n",
    "        arr: Value array with dimensions (r,c,3)\n",
    "        filename: Output filename for new raster \n",
    "    '''\n",
    "\n",
    "    # Open template\n",
    "    t = gdal.Open(template)\n",
    "\n",
    "    # Get geotiff driver\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    # Create new raster\n",
    "    r = driver.Create(filename, t.RasterXSize, t.RasterYSize, 3, gdal.GDT_Byte,['COMPRESS=LZW'])\n",
    "\n",
    "    # Set metadata\n",
    "    r.SetGeoTransform(t.GetGeoTransform())\n",
    "    r.SetProjection(t.GetProjection())\n",
    "\n",
    "    # loop through bands and write new values\n",
    "    for bix in range(3):\n",
    "\n",
    "        rb = r.GetRasterBand(bix+1)\n",
    "\n",
    "        # Write array\n",
    "        rb.WriteArray(arr[...,bix])\n",
    "\n",
    "    # Close datasets\n",
    "    t = None\n",
    "    r = None\n",
    "    rb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model', custom_objects={'f1':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicts = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOSTRA AS MASCARAS DAS IMAGENS\n",
    "def show_mask(test_predicts):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = 'Predicted Mask'\n",
    "    plt.title(title)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(test_predicts))\n",
    "    plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORMA MASCARA OUTPUT EM RASTER\n",
    "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array):\n",
    "\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX = rasterOrigin[0]\n",
    "    originY = rasterOrigin[1]\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(4326)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file_input in enumerate(test_frames_list):\n",
    "    file_output = file_input.replace('test_frames','predict')\n",
    "    aux = gdal.Open(file_input)\n",
    "    geo_t = aux.GetGeoTransform()\n",
    "    origin = (geo_t[0],geo_t[3])\n",
    "    px_width = geo_t[1]\n",
    "    px_height = geo_t[5]\n",
    "    array = test_predicts[i,:, :, 0]\n",
    "    array2raster(file_output,origin,px_width,px_height,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, file_input in enumerate(test_frames_list):\n",
    "    file_output = file_input.replace('test_frames','predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnt_images = 500\n",
    "for i in range(qnt_images):\n",
    "    b, g, r  = batch_test_images[i][:, :, 0], batch_test_images[i][:, :, 1], batch_test_images[i][:, :, 2]\n",
    "    rgb = np.dstack((r,g,b))\n",
    "    show_images([rgb, mask_true_image_test[i], mask_predict[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    show_images([test_predicts[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_predicts[321]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = gdal.Open('D:\\\\cbers_data\\\\DataSetModelo\\\\test_masks\\\\CBERS_4A_WFI_20201020_205_116_L4_0_51_52_.tif').ReadAsArray()\n",
    "teste = np.expand_dims(teste,2)\n",
    "show_mask(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensoes subscenes\n",
    "DIMENSION = 256\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAMINHO DOS ARQUIVOS DE ENTRADA (IMAGEM COMPLETA) (ENTRADA)\n",
    "production_frame_path = \"D:/cbers_data/DataSetModelo/ProductionFrames/\"\n",
    "\n",
    "#CAMINHO QUE ARMAZENARÁ AS SUBCENAS DA IMAGEM DE ENTRADA (SAIDA)\n",
    "production_cropped_frame_path = \"D:/cbers_data/DataSetModelo/ProductionCroppedFrames/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função responsável por cortar as imagens de entrada e salvá-las num diretório de saída\n",
    "def save_cropped_production_images(input_path_base, output_path_base, DIMENSION):\n",
    "    #Pega lista de imagens a serem cortadas\n",
    "    raw_images_list_name = os.listdir(production_frame_path)\n",
    "    for frame_name in raw_images_list_name:\n",
    "        #Pasta de saída terá mesmo nome do arquivo de entrada (porém sem o .tif)\n",
    "        output_path = output_path_base + frame_name.split('.')[0]+\"/\"\n",
    "        #Caminho dos arquivos de entrada (imagens cruas)\n",
    "        input_path = input_path_base + frame_name\n",
    "        #Abre a imagem de entrada\n",
    "        raw_scene = gdal.Open(input_path)\n",
    "        #Cria uma pasta com o nome do arquivo de entrada\n",
    "        if not os.path.isdir(output_path):\n",
    "            os.mkdir(output_path)\n",
    "        #Corta as imagens de entrada e as salva no diretório de saída\n",
    "        crop_image_rgbn(output_path, raw_scene, frame_name.split(\".\")[0], DIMENSION)\n",
    "        \n",
    "#Chamada da função\n",
    "save_cropped_production_images(production_frame_path,production_cropped_frame_path, DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTA QUE CONTEM O CAMINHO DE CADA SUBCENA GERADA (ENTRADAS)\n",
    "subscenes_path_list = [production_cropped_frame_path + file_name + \"/\" for file_name in os.listdir(production_cropped_frame_path)]\n",
    "\n",
    "#CAMINHO QUE ARMAZENARÁ AS MASCARAS DAS SUBCENAS (SAIDA)\n",
    "production_cropped_mask_path = \"D:/cbers_data/DataSetModelo/ProductionCroppedMasks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função responsável por chamar o modelo para gerar as mascaras e a salvar no diretório de saída\n",
    "def save_production_cropped_masks(input_dir_list, output_path):\n",
    "    #FOR que caminha entre os diretórios das subcenas\n",
    "    for i, dir_name in enumerate(input_dir_list):\n",
    "        #FOR que entrou no diretório de uma subcenas e caminha por elas\n",
    "        input_file_list = os.listdir(dir_name)\n",
    "        for j, file_name in enumerate(input_file_list):\n",
    "            subscene = gdal.Open(dir_name+file_name)\n",
    "            subscene_array = subscene.ReadAsArray().transpose((1,2,0))\n",
    "            subscene_normalized =  cv2.normalize(subscene_array, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            #Dimensões são adequadas para o predict do modelo\n",
    "            subscene_expanded = np.expand_dims(subscene_normalized, axis=0)\n",
    "            subscene_mask = model.predict(subscene_expanded)\n",
    "            \n",
    "            ##Etapa para configurar o .tif das mascaras\n",
    "            driver = gdal.GetDriverByName(\"GTiff\")\n",
    "            metadata = driver.GetMetadata()\n",
    "            \n",
    "            #Transforma shape da mascara de (1,256,256,1) para (256,256)\n",
    "            subscene_mask = subscene_mask.squeeze()\n",
    "            #NOME DA CENA ORIGINAL (IMAGEM INTEIRA)\n",
    "            original_scene_name = file_name.split(\"rgbn\")[0]+\"rgbn\"\n",
    "            #Cria uma pasta com o nome do arquivo original (IMAGEM COMPLETA)\n",
    "            if not os.path.isdir(output_path + original_scene_name):\n",
    "                os.mkdir(output_path + original_scene_name)\n",
    "            #Cria um raster (.tif) da mascara com o mesmo tamanho da subscena\n",
    "            subscene_mask_raster = driver.Create(output_path + original_scene_name + \"/\" + file_name,\n",
    "                                subscene.RasterXSize,\n",
    "                                subscene.RasterYSize,\n",
    "                                1, #Numero de bandas da mascara\n",
    "                                gdal.GDT_Float32)\n",
    "            #COPIA AS PROJEÇÕES DA SUBSCENA\n",
    "            subscene_mask_raster.SetProjection(subscene.GetProjectionRef())\n",
    "            subscene_mask_raster.SetGeoTransform(subscene.GetGeoTransform()) \n",
    "            \n",
    "            #Get the band to write to\n",
    "            #out_band = subscene.GetRasterBand(1)\n",
    "            #ESCREVE A MASCARA EM DISCO\n",
    "            subscene_mask_raster.WriteArray(subscene_mask)\n",
    "            \n",
    "save_production_cropped_masks(subscenes_path_list, production_cropped_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTA QUE CONTEM O CAMINHO DE CADA MASCARA GERADA (ENTRADAS)\n",
    "masks_path_list = [production_cropped_mask_path + file_name + \"/\" for file_name in os.listdir(production_cropped_mask_path)]\n",
    "\n",
    "\n",
    "# Caminho para o diretório onde deverá ser salvo a máscara após o mosaico (SAIDA)\n",
    "mask_mosaic_path = \"D:/cbers_data/DataSetModelo/MergeFile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, folder_name in enumerate(masks_path_list):\n",
    "    folder_input_list = os.listdir(folder_name)\n",
    "    files_to_mosaic_path = [folder_name + file_name  for file_name in folder_input_list]\n",
    "    print(folder_input_list[0].split('rgbn')[0] + \"rgbn/\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osgeo_utils.gdal_merge\n",
    "def mount_mosaic_of_masks(input_path, output_path):\n",
    "    for i, folder_name in enumerate(input_path):\n",
    "        files_to_mosaic = os.listdir(folder_name)\n",
    "        files_to_mosaic_path = [folder_name + file_name  for file_name in files_to_mosaic]\n",
    "        #Cria uma pasta com o nome do arquivo original (IMAGEM COMPLETA)\n",
    "        original_file_name = files_to_mosaic[0].split(\"rgbn\")[0]+\"rgbn\"\n",
    "        if not os.path.isdir(output_path + original_file_name):\n",
    "            os.mkdir(output_path + original_file_name)\n",
    "        #ESCREVE EM DISCO\n",
    "        print(output_path + original_file_name + \"/\" + original_file_name + \n",
    "                      \".tif\")\n",
    "        g = gdal.Warp(output_path + original_file_name + \"/\" + original_file_name + \n",
    "                      \".tif\", files_to_mosaic_path, format=\"GTiff\")\n",
    "        g = None # Close file and flush to disk\n",
    "        \n",
    "mount_mosaic_of_masks(masks_path_list, mask_mosaic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
